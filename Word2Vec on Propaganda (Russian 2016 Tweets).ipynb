{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the effects of Word2Vec on propaganda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a function to convert a random article to a cohesive list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_to_wordlist(text, remove_stopwords = False):\n",
    "    \"\"\"\n",
    "    Converts an article into a sequence of words\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Remove HTML\n",
    "    # text = BeautifulSoup(text).get_text()\n",
    "\n",
    "    # 2. Remove non-letters\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    # 3. Convert words to lowercase and split\n",
    "    words = text.lower().split()\n",
    "\n",
    "    # 4. (Optional) Remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    # 5. Return the list\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the function on our propaganda text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22722162 words\n",
      "2106034\n"
     ]
    }
   ],
   "source": [
    "tweet_file = open('tweets-large.txt', 'r')\n",
    "\n",
    "clean_tweets = []\n",
    "tweet_text = ''\n",
    "for tweet in tweet_file:\n",
    "    tweet_text += tweet + ' '\n",
    "    clean_tweets.append(tweet)\n",
    "    \n",
    "print(f'There are {len(text_to_wordlist(tweet_text))} words')\n",
    "print(len(clean_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add a function to parse the text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "# nltk.download()\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def text_to_sentences(tweet, tokenizer, remove_stopwords = False):\n",
    "    \"\"\"\n",
    "    Splits an article into parsed sentences\n",
    "    Returns a list of sentences\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph\n",
    "    raw_sentences = tokenizer.tokenize(tweet.strip())\n",
    "\n",
    "    # 2. Loop over every sentence\n",
    "    sentences = []\n",
    "    for sentence in raw_sentences:\n",
    "        if len(sentence) != 0:\n",
    "            sentences += text_to_wordlist(sentence, remove_stopwords)\n",
    "\n",
    "    # 3. Return the list\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2106034 sentences\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "for tweet in clean_tweets:\n",
    "    sentences.append(text_to_sentences(tweet, tokenizer, True))\n",
    "\n",
    "print(f'There are {len(sentences)} sentences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train and store the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-15 14:53:49,725 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-03-15 14:53:49,726 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2020-03-15 14:53:49,727 : INFO : collecting all words and their counts\n",
      "2020-03-15 14:53:49,728 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-03-15 14:53:49,742 : INFO : PROGRESS: at sentence #10000, processed 72754 words, keeping 16219 word types\n",
      "2020-03-15 14:53:49,759 : INFO : PROGRESS: at sentence #20000, processed 144738 words, keeping 26002 word types\n",
      "2020-03-15 14:53:49,777 : INFO : PROGRESS: at sentence #30000, processed 230874 words, keeping 29868 word types\n",
      "2020-03-15 14:53:49,789 : INFO : PROGRESS: at sentence #40000, processed 295384 words, keeping 34253 word types\n",
      "2020-03-15 14:53:49,802 : INFO : PROGRESS: at sentence #50000, processed 371770 words, keeping 38730 word types\n",
      "2020-03-15 14:53:49,818 : INFO : PROGRESS: at sentence #60000, processed 457024 words, keeping 44435 word types\n",
      "2020-03-15 14:53:49,831 : INFO : PROGRESS: at sentence #70000, processed 527731 words, keeping 48886 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-15 14:53:49,845 : INFO : PROGRESS: at sentence #80000, processed 603931 words, keeping 53004 word types\n",
      "2020-03-15 14:53:49,862 : INFO : PROGRESS: at sentence #90000, processed 700959 words, keeping 57964 word types\n",
      "2020-03-15 14:53:49,880 : INFO : PROGRESS: at sentence #100000, processed 795413 words, keeping 62909 word types\n",
      "2020-03-15 14:53:49,898 : INFO : PROGRESS: at sentence #110000, processed 891267 words, keeping 67731 word types\n",
      "2020-03-15 14:53:49,914 : INFO : PROGRESS: at sentence #120000, processed 981608 words, keeping 70859 word types\n",
      "2020-03-15 14:53:49,929 : INFO : PROGRESS: at sentence #130000, processed 1066278 words, keeping 73770 word types\n",
      "2020-03-15 14:53:49,940 : INFO : PROGRESS: at sentence #140000, processed 1122244 words, keeping 75400 word types\n",
      "2020-03-15 14:53:49,955 : INFO : PROGRESS: at sentence #150000, processed 1203878 words, keeping 78400 word types\n",
      "2020-03-15 14:53:49,971 : INFO : PROGRESS: at sentence #160000, processed 1293627 words, keeping 84055 word types\n",
      "2020-03-15 14:53:49,984 : INFO : PROGRESS: at sentence #170000, processed 1361778 words, keeping 87133 word types\n",
      "2020-03-15 14:53:50,001 : INFO : PROGRESS: at sentence #180000, processed 1439705 words, keeping 89659 word types\n",
      "2020-03-15 14:53:50,015 : INFO : PROGRESS: at sentence #190000, processed 1515415 words, keeping 92069 word types\n",
      "2020-03-15 14:53:50,030 : INFO : PROGRESS: at sentence #200000, processed 1598133 words, keeping 94090 word types\n",
      "2020-03-15 14:53:50,042 : INFO : PROGRESS: at sentence #210000, processed 1664047 words, keeping 95070 word types\n",
      "2020-03-15 14:53:50,055 : INFO : PROGRESS: at sentence #220000, processed 1735604 words, keeping 96655 word types\n",
      "2020-03-15 14:53:50,068 : INFO : PROGRESS: at sentence #230000, processed 1803699 words, keeping 97816 word types\n",
      "2020-03-15 14:53:50,084 : INFO : PROGRESS: at sentence #240000, processed 1879594 words, keeping 100242 word types\n",
      "2020-03-15 14:53:50,100 : INFO : PROGRESS: at sentence #250000, processed 1969005 words, keeping 101656 word types\n",
      "2020-03-15 14:53:50,117 : INFO : PROGRESS: at sentence #260000, processed 2047909 words, keeping 103807 word types\n",
      "2020-03-15 14:53:50,139 : INFO : PROGRESS: at sentence #270000, processed 2135793 words, keeping 112160 word types\n",
      "2020-03-15 14:53:50,157 : INFO : PROGRESS: at sentence #280000, processed 2219243 words, keeping 120166 word types\n",
      "2020-03-15 14:53:50,171 : INFO : PROGRESS: at sentence #290000, processed 2289129 words, keeping 122428 word types\n",
      "2020-03-15 14:53:50,187 : INFO : PROGRESS: at sentence #300000, processed 2373878 words, keeping 126783 word types\n",
      "2020-03-15 14:53:50,201 : INFO : PROGRESS: at sentence #310000, processed 2443851 words, keeping 131733 word types\n",
      "2020-03-15 14:53:50,216 : INFO : PROGRESS: at sentence #320000, processed 2526347 words, keeping 133247 word types\n",
      "2020-03-15 14:53:50,231 : INFO : PROGRESS: at sentence #330000, processed 2601556 words, keeping 134717 word types\n",
      "2020-03-15 14:53:50,244 : INFO : PROGRESS: at sentence #340000, processed 2664458 words, keeping 136584 word types\n",
      "2020-03-15 14:53:50,254 : INFO : PROGRESS: at sentence #350000, processed 2709188 words, keeping 137776 word types\n",
      "2020-03-15 14:53:50,269 : INFO : PROGRESS: at sentence #360000, processed 2792931 words, keeping 139578 word types\n",
      "2020-03-15 14:53:50,280 : INFO : PROGRESS: at sentence #370000, processed 2846727 words, keeping 140473 word types\n",
      "2020-03-15 14:53:50,301 : INFO : PROGRESS: at sentence #380000, processed 2926508 words, keeping 142400 word types\n",
      "2020-03-15 14:53:50,321 : INFO : PROGRESS: at sentence #390000, processed 3008626 words, keeping 144025 word types\n",
      "2020-03-15 14:53:50,339 : INFO : PROGRESS: at sentence #400000, processed 3087621 words, keeping 145564 word types\n",
      "2020-03-15 14:53:50,348 : INFO : PROGRESS: at sentence #410000, processed 3118668 words, keeping 145999 word types\n",
      "2020-03-15 14:53:50,367 : INFO : PROGRESS: at sentence #420000, processed 3190769 words, keeping 147242 word types\n",
      "2020-03-15 14:53:50,380 : INFO : PROGRESS: at sentence #430000, processed 3255031 words, keeping 148991 word types\n",
      "2020-03-15 14:53:50,396 : INFO : PROGRESS: at sentence #440000, processed 3339282 words, keeping 150087 word types\n",
      "2020-03-15 14:53:50,411 : INFO : PROGRESS: at sentence #450000, processed 3424167 words, keeping 151091 word types\n",
      "2020-03-15 14:53:50,426 : INFO : PROGRESS: at sentence #460000, processed 3504306 words, keeping 152288 word types\n",
      "2020-03-15 14:53:50,436 : INFO : PROGRESS: at sentence #470000, processed 3546484 words, keeping 154045 word types\n",
      "2020-03-15 14:53:50,451 : INFO : PROGRESS: at sentence #480000, processed 3621102 words, keeping 155901 word types\n",
      "2020-03-15 14:53:50,465 : INFO : PROGRESS: at sentence #490000, processed 3697787 words, keeping 156637 word types\n",
      "2020-03-15 14:53:50,491 : INFO : PROGRESS: at sentence #500000, processed 3787463 words, keeping 157340 word types\n",
      "2020-03-15 14:53:50,507 : INFO : PROGRESS: at sentence #510000, processed 3884886 words, keeping 157690 word types\n",
      "2020-03-15 14:53:50,525 : INFO : PROGRESS: at sentence #520000, processed 3983594 words, keeping 158123 word types\n",
      "2020-03-15 14:53:50,543 : INFO : PROGRESS: at sentence #530000, processed 4080650 words, keeping 158408 word types\n",
      "2020-03-15 14:53:50,561 : INFO : PROGRESS: at sentence #540000, processed 4171106 words, keeping 158884 word types\n",
      "2020-03-15 14:53:50,576 : INFO : PROGRESS: at sentence #550000, processed 4251269 words, keeping 159669 word types\n",
      "2020-03-15 14:53:50,593 : INFO : PROGRESS: at sentence #560000, processed 4331562 words, keeping 160455 word types\n",
      "2020-03-15 14:53:50,606 : INFO : PROGRESS: at sentence #570000, processed 4398789 words, keeping 161049 word types\n",
      "2020-03-15 14:53:50,616 : INFO : PROGRESS: at sentence #580000, processed 4444590 words, keeping 162400 word types\n",
      "2020-03-15 14:53:50,628 : INFO : PROGRESS: at sentence #590000, processed 4505551 words, keeping 163126 word types\n",
      "2020-03-15 14:53:50,651 : INFO : PROGRESS: at sentence #600000, processed 4582182 words, keeping 163250 word types\n",
      "2020-03-15 14:53:50,668 : INFO : PROGRESS: at sentence #610000, processed 4667686 words, keeping 163383 word types\n",
      "2020-03-15 14:53:50,686 : INFO : PROGRESS: at sentence #620000, processed 4756288 words, keeping 163506 word types\n",
      "2020-03-15 14:53:50,701 : INFO : PROGRESS: at sentence #630000, processed 4834949 words, keeping 164174 word types\n",
      "2020-03-15 14:53:50,714 : INFO : PROGRESS: at sentence #640000, processed 4897053 words, keeping 165099 word types\n",
      "2020-03-15 14:53:50,733 : INFO : PROGRESS: at sentence #650000, processed 4976169 words, keeping 166098 word types\n",
      "2020-03-15 14:53:50,754 : INFO : PROGRESS: at sentence #660000, processed 5046519 words, keeping 170623 word types\n",
      "2020-03-15 14:53:50,770 : INFO : PROGRESS: at sentence #670000, processed 5103780 words, keeping 171558 word types\n",
      "2020-03-15 14:53:50,788 : INFO : PROGRESS: at sentence #680000, processed 5174498 words, keeping 172770 word types\n",
      "2020-03-15 14:53:50,809 : INFO : PROGRESS: at sentence #690000, processed 5276839 words, keeping 174886 word types\n",
      "2020-03-15 14:53:50,824 : INFO : PROGRESS: at sentence #700000, processed 5339581 words, keeping 175729 word types\n",
      "2020-03-15 14:53:50,842 : INFO : PROGRESS: at sentence #710000, processed 5421018 words, keeping 177841 word types\n",
      "2020-03-15 14:53:50,855 : INFO : PROGRESS: at sentence #720000, processed 5476917 words, keeping 178360 word types\n",
      "2020-03-15 14:53:50,870 : INFO : PROGRESS: at sentence #730000, processed 5548492 words, keeping 180129 word types\n",
      "2020-03-15 14:53:50,884 : INFO : PROGRESS: at sentence #740000, processed 5612971 words, keeping 181331 word types\n",
      "2020-03-15 14:53:50,900 : INFO : PROGRESS: at sentence #750000, processed 5682381 words, keeping 182942 word types\n",
      "2020-03-15 14:53:50,916 : INFO : PROGRESS: at sentence #760000, processed 5764763 words, keeping 183640 word types\n",
      "2020-03-15 14:53:50,934 : INFO : PROGRESS: at sentence #770000, processed 5857461 words, keeping 184985 word types\n",
      "2020-03-15 14:53:50,954 : INFO : PROGRESS: at sentence #780000, processed 5943704 words, keeping 188158 word types\n",
      "2020-03-15 14:53:50,970 : INFO : PROGRESS: at sentence #790000, processed 6006110 words, keeping 189381 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-15 14:53:50,985 : INFO : PROGRESS: at sentence #800000, processed 6077255 words, keeping 190164 word types\n",
      "2020-03-15 14:53:50,998 : INFO : PROGRESS: at sentence #810000, processed 6141380 words, keeping 190901 word types\n",
      "2020-03-15 14:53:51,014 : INFO : PROGRESS: at sentence #820000, processed 6200276 words, keeping 191433 word types\n",
      "2020-03-15 14:53:51,023 : INFO : PROGRESS: at sentence #830000, processed 6245648 words, keeping 192183 word types\n",
      "2020-03-15 14:53:51,038 : INFO : PROGRESS: at sentence #840000, processed 6326221 words, keeping 193865 word types\n",
      "2020-03-15 14:53:51,060 : INFO : PROGRESS: at sentence #850000, processed 6403791 words, keeping 195298 word types\n",
      "2020-03-15 14:53:51,079 : INFO : PROGRESS: at sentence #860000, processed 6473978 words, keeping 197690 word types\n",
      "2020-03-15 14:53:51,090 : INFO : PROGRESS: at sentence #870000, processed 6524148 words, keeping 199434 word types\n",
      "2020-03-15 14:53:51,101 : INFO : PROGRESS: at sentence #880000, processed 6567510 words, keeping 200103 word types\n",
      "2020-03-15 14:53:51,112 : INFO : PROGRESS: at sentence #890000, processed 6614944 words, keeping 200712 word types\n",
      "2020-03-15 14:53:51,128 : INFO : PROGRESS: at sentence #900000, processed 6694576 words, keeping 202403 word types\n",
      "2020-03-15 14:53:51,147 : INFO : PROGRESS: at sentence #910000, processed 6777346 words, keeping 203604 word types\n",
      "2020-03-15 14:53:51,164 : INFO : PROGRESS: at sentence #920000, processed 6847899 words, keeping 203764 word types\n",
      "2020-03-15 14:53:51,180 : INFO : PROGRESS: at sentence #930000, processed 6916116 words, keeping 203859 word types\n",
      "2020-03-15 14:53:51,194 : INFO : PROGRESS: at sentence #940000, processed 6988439 words, keeping 204282 word types\n",
      "2020-03-15 14:53:51,208 : INFO : PROGRESS: at sentence #950000, processed 7058919 words, keeping 204533 word types\n",
      "2020-03-15 14:53:51,225 : INFO : PROGRESS: at sentence #960000, processed 7136703 words, keeping 205263 word types\n",
      "2020-03-15 14:53:51,241 : INFO : PROGRESS: at sentence #970000, processed 7219695 words, keeping 206020 word types\n",
      "2020-03-15 14:53:51,256 : INFO : PROGRESS: at sentence #980000, processed 7298055 words, keeping 206340 word types\n",
      "2020-03-15 14:53:51,270 : INFO : PROGRESS: at sentence #990000, processed 7367441 words, keeping 206728 word types\n",
      "2020-03-15 14:53:51,286 : INFO : PROGRESS: at sentence #1000000, processed 7445663 words, keeping 207557 word types\n",
      "2020-03-15 14:53:51,302 : INFO : PROGRESS: at sentence #1010000, processed 7532945 words, keeping 209104 word types\n",
      "2020-03-15 14:53:51,319 : INFO : PROGRESS: at sentence #1020000, processed 7622655 words, keeping 210158 word types\n",
      "2020-03-15 14:53:51,332 : INFO : PROGRESS: at sentence #1030000, processed 7690270 words, keeping 210621 word types\n",
      "2020-03-15 14:53:51,349 : INFO : PROGRESS: at sentence #1040000, processed 7772219 words, keeping 211802 word types\n",
      "2020-03-15 14:53:51,373 : INFO : PROGRESS: at sentence #1050000, processed 7857784 words, keeping 212216 word types\n",
      "2020-03-15 14:53:51,393 : INFO : PROGRESS: at sentence #1060000, processed 7935392 words, keeping 212803 word types\n",
      "2020-03-15 14:53:51,412 : INFO : PROGRESS: at sentence #1070000, processed 8009549 words, keeping 213208 word types\n",
      "2020-03-15 14:53:51,430 : INFO : PROGRESS: at sentence #1080000, processed 8082573 words, keeping 213389 word types\n",
      "2020-03-15 14:53:51,448 : INFO : PROGRESS: at sentence #1090000, processed 8164626 words, keeping 215165 word types\n",
      "2020-03-15 14:53:51,466 : INFO : PROGRESS: at sentence #1100000, processed 8220557 words, keeping 215979 word types\n",
      "2020-03-15 14:53:51,481 : INFO : PROGRESS: at sentence #1110000, processed 8285957 words, keeping 216357 word types\n",
      "2020-03-15 14:53:51,489 : INFO : PROGRESS: at sentence #1120000, processed 8315859 words, keeping 216730 word types\n",
      "2020-03-15 14:53:51,510 : INFO : PROGRESS: at sentence #1130000, processed 8403180 words, keeping 218307 word types\n",
      "2020-03-15 14:53:51,533 : INFO : PROGRESS: at sentence #1140000, processed 8512212 words, keeping 219736 word types\n",
      "2020-03-15 14:53:51,555 : INFO : PROGRESS: at sentence #1150000, processed 8627839 words, keeping 220882 word types\n",
      "2020-03-15 14:53:51,576 : INFO : PROGRESS: at sentence #1160000, processed 8710230 words, keeping 221589 word types\n",
      "2020-03-15 14:53:51,592 : INFO : PROGRESS: at sentence #1170000, processed 8782627 words, keeping 222189 word types\n",
      "2020-03-15 14:53:51,608 : INFO : PROGRESS: at sentence #1180000, processed 8861237 words, keeping 222643 word types\n",
      "2020-03-15 14:53:51,626 : INFO : PROGRESS: at sentence #1190000, processed 8946746 words, keeping 223240 word types\n",
      "2020-03-15 14:53:51,642 : INFO : PROGRESS: at sentence #1200000, processed 9021163 words, keeping 223508 word types\n",
      "2020-03-15 14:53:51,657 : INFO : PROGRESS: at sentence #1210000, processed 9096290 words, keeping 223807 word types\n",
      "2020-03-15 14:53:51,673 : INFO : PROGRESS: at sentence #1220000, processed 9174873 words, keeping 224080 word types\n",
      "2020-03-15 14:53:51,689 : INFO : PROGRESS: at sentence #1230000, processed 9249008 words, keeping 224299 word types\n",
      "2020-03-15 14:53:51,706 : INFO : PROGRESS: at sentence #1240000, processed 9329052 words, keeping 224658 word types\n",
      "2020-03-15 14:53:51,725 : INFO : PROGRESS: at sentence #1250000, processed 9410059 words, keeping 225702 word types\n",
      "2020-03-15 14:53:51,743 : INFO : PROGRESS: at sentence #1260000, processed 9489513 words, keeping 226193 word types\n",
      "2020-03-15 14:53:51,764 : INFO : PROGRESS: at sentence #1270000, processed 9558918 words, keeping 228498 word types\n",
      "2020-03-15 14:53:51,779 : INFO : PROGRESS: at sentence #1280000, processed 9621005 words, keeping 228868 word types\n",
      "2020-03-15 14:53:51,798 : INFO : PROGRESS: at sentence #1290000, processed 9700570 words, keeping 229212 word types\n",
      "2020-03-15 14:53:51,813 : INFO : PROGRESS: at sentence #1300000, processed 9769781 words, keeping 229791 word types\n",
      "2020-03-15 14:53:51,830 : INFO : PROGRESS: at sentence #1310000, processed 9843875 words, keeping 231565 word types\n",
      "2020-03-15 14:53:51,845 : INFO : PROGRESS: at sentence #1320000, processed 9908372 words, keeping 232027 word types\n",
      "2020-03-15 14:53:51,862 : INFO : PROGRESS: at sentence #1330000, processed 9986577 words, keeping 232669 word types\n",
      "2020-03-15 14:53:51,886 : INFO : PROGRESS: at sentence #1340000, processed 10100233 words, keeping 234287 word types\n",
      "2020-03-15 14:53:51,909 : INFO : PROGRESS: at sentence #1350000, processed 10181976 words, keeping 235872 word types\n",
      "2020-03-15 14:53:51,928 : INFO : PROGRESS: at sentence #1360000, processed 10263486 words, keeping 236718 word types\n",
      "2020-03-15 14:53:51,945 : INFO : PROGRESS: at sentence #1370000, processed 10341305 words, keeping 237095 word types\n",
      "2020-03-15 14:53:51,964 : INFO : PROGRESS: at sentence #1380000, processed 10414150 words, keeping 237318 word types\n",
      "2020-03-15 14:53:51,984 : INFO : PROGRESS: at sentence #1390000, processed 10487889 words, keeping 237673 word types\n",
      "2020-03-15 14:53:51,998 : INFO : PROGRESS: at sentence #1400000, processed 10562637 words, keeping 238013 word types\n",
      "2020-03-15 14:53:52,013 : INFO : PROGRESS: at sentence #1410000, processed 10637620 words, keeping 238255 word types\n",
      "2020-03-15 14:53:52,036 : INFO : PROGRESS: at sentence #1420000, processed 10707428 words, keeping 238494 word types\n",
      "2020-03-15 14:53:52,051 : INFO : PROGRESS: at sentence #1430000, processed 10775571 words, keeping 239007 word types\n",
      "2020-03-15 14:53:52,062 : INFO : PROGRESS: at sentence #1440000, processed 10829229 words, keeping 239589 word types\n",
      "2020-03-15 14:53:52,072 : INFO : PROGRESS: at sentence #1450000, processed 10872964 words, keeping 240215 word types\n",
      "2020-03-15 14:53:52,084 : INFO : PROGRESS: at sentence #1460000, processed 10921323 words, keeping 240858 word types\n",
      "2020-03-15 14:53:52,098 : INFO : PROGRESS: at sentence #1470000, processed 10985523 words, keeping 243023 word types\n",
      "2020-03-15 14:53:52,117 : INFO : PROGRESS: at sentence #1480000, processed 11071530 words, keeping 244156 word types\n",
      "2020-03-15 14:53:52,138 : INFO : PROGRESS: at sentence #1490000, processed 11151589 words, keeping 245036 word types\n",
      "2020-03-15 14:53:52,155 : INFO : PROGRESS: at sentence #1500000, processed 11229174 words, keeping 246250 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-15 14:53:52,172 : INFO : PROGRESS: at sentence #1510000, processed 11311881 words, keeping 247190 word types\n",
      "2020-03-15 14:53:52,189 : INFO : PROGRESS: at sentence #1520000, processed 11393078 words, keeping 247474 word types\n",
      "2020-03-15 14:53:52,205 : INFO : PROGRESS: at sentence #1530000, processed 11474445 words, keeping 247812 word types\n",
      "2020-03-15 14:53:52,220 : INFO : PROGRESS: at sentence #1540000, processed 11555124 words, keeping 248172 word types\n",
      "2020-03-15 14:53:52,235 : INFO : PROGRESS: at sentence #1550000, processed 11629501 words, keeping 248438 word types\n",
      "2020-03-15 14:53:52,247 : INFO : PROGRESS: at sentence #1560000, processed 11687739 words, keeping 248870 word types\n",
      "2020-03-15 14:53:52,259 : INFO : PROGRESS: at sentence #1570000, processed 11746595 words, keeping 249236 word types\n",
      "2020-03-15 14:53:52,272 : INFO : PROGRESS: at sentence #1580000, processed 11815970 words, keeping 249640 word types\n",
      "2020-03-15 14:53:52,287 : INFO : PROGRESS: at sentence #1590000, processed 11886777 words, keeping 250046 word types\n",
      "2020-03-15 14:53:52,298 : INFO : PROGRESS: at sentence #1600000, processed 11941310 words, keeping 250648 word types\n",
      "2020-03-15 14:53:52,313 : INFO : PROGRESS: at sentence #1610000, processed 12020460 words, keeping 251107 word types\n",
      "2020-03-15 14:53:52,331 : INFO : PROGRESS: at sentence #1620000, processed 12108467 words, keeping 252273 word types\n",
      "2020-03-15 14:53:52,347 : INFO : PROGRESS: at sentence #1630000, processed 12194686 words, keeping 253522 word types\n",
      "2020-03-15 14:53:52,367 : INFO : PROGRESS: at sentence #1640000, processed 12307916 words, keeping 255123 word types\n",
      "2020-03-15 14:53:52,380 : INFO : PROGRESS: at sentence #1650000, processed 12366964 words, keeping 255701 word types\n",
      "2020-03-15 14:53:52,404 : INFO : PROGRESS: at sentence #1660000, processed 12446693 words, keeping 256364 word types\n",
      "2020-03-15 14:53:52,421 : INFO : PROGRESS: at sentence #1670000, processed 12506842 words, keeping 256728 word types\n",
      "2020-03-15 14:53:52,439 : INFO : PROGRESS: at sentence #1680000, processed 12568481 words, keeping 257267 word types\n",
      "2020-03-15 14:53:52,460 : INFO : PROGRESS: at sentence #1690000, processed 12646531 words, keeping 259264 word types\n",
      "2020-03-15 14:53:52,477 : INFO : PROGRESS: at sentence #1700000, processed 12714079 words, keeping 259907 word types\n",
      "2020-03-15 14:53:52,495 : INFO : PROGRESS: at sentence #1710000, processed 12777266 words, keeping 260297 word types\n",
      "2020-03-15 14:53:52,521 : INFO : PROGRESS: at sentence #1720000, processed 12874426 words, keeping 262331 word types\n",
      "2020-03-15 14:53:52,543 : INFO : PROGRESS: at sentence #1730000, processed 12969917 words, keeping 263857 word types\n",
      "2020-03-15 14:53:52,562 : INFO : PROGRESS: at sentence #1740000, processed 13046728 words, keeping 264632 word types\n",
      "2020-03-15 14:53:52,587 : INFO : PROGRESS: at sentence #1750000, processed 13138922 words, keeping 266360 word types\n",
      "2020-03-15 14:53:52,606 : INFO : PROGRESS: at sentence #1760000, processed 13204419 words, keeping 267279 word types\n",
      "2020-03-15 14:53:52,624 : INFO : PROGRESS: at sentence #1770000, processed 13285028 words, keeping 267897 word types\n",
      "2020-03-15 14:53:52,638 : INFO : PROGRESS: at sentence #1780000, processed 13340125 words, keeping 272514 word types\n",
      "2020-03-15 14:53:52,651 : INFO : PROGRESS: at sentence #1790000, processed 13395844 words, keeping 277284 word types\n",
      "2020-03-15 14:53:52,670 : INFO : PROGRESS: at sentence #1800000, processed 13452859 words, keeping 282270 word types\n",
      "2020-03-15 14:53:52,686 : INFO : PROGRESS: at sentence #1810000, processed 13515398 words, keeping 293428 word types\n",
      "2020-03-15 14:53:52,702 : INFO : PROGRESS: at sentence #1820000, processed 13578602 words, keeping 303053 word types\n",
      "2020-03-15 14:53:52,721 : INFO : PROGRESS: at sentence #1830000, processed 13642639 words, keeping 312618 word types\n",
      "2020-03-15 14:53:52,734 : INFO : PROGRESS: at sentence #1840000, processed 13699617 words, keeping 314844 word types\n",
      "2020-03-15 14:53:52,747 : INFO : PROGRESS: at sentence #1850000, processed 13757659 words, keeping 318822 word types\n",
      "2020-03-15 14:53:52,762 : INFO : PROGRESS: at sentence #1860000, processed 13812429 words, keeping 326915 word types\n",
      "2020-03-15 14:53:52,784 : INFO : PROGRESS: at sentence #1870000, processed 13878131 words, keeping 334038 word types\n",
      "2020-03-15 14:53:52,803 : INFO : PROGRESS: at sentence #1880000, processed 13958340 words, keeping 336434 word types\n",
      "2020-03-15 14:53:52,818 : INFO : PROGRESS: at sentence #1890000, processed 14022452 words, keeping 340532 word types\n",
      "2020-03-15 14:53:52,831 : INFO : PROGRESS: at sentence #1900000, processed 14078357 words, keeping 344384 word types\n",
      "2020-03-15 14:53:52,846 : INFO : PROGRESS: at sentence #1910000, processed 14141845 words, keeping 345629 word types\n",
      "2020-03-15 14:53:52,867 : INFO : PROGRESS: at sentence #1920000, processed 14221892 words, keeping 348052 word types\n",
      "2020-03-15 14:53:52,883 : INFO : PROGRESS: at sentence #1930000, processed 14281043 words, keeping 348372 word types\n",
      "2020-03-15 14:53:52,907 : INFO : PROGRESS: at sentence #1940000, processed 14357479 words, keeping 350357 word types\n",
      "2020-03-15 14:53:52,926 : INFO : PROGRESS: at sentence #1950000, processed 14439560 words, keeping 354478 word types\n",
      "2020-03-15 14:53:52,943 : INFO : PROGRESS: at sentence #1960000, processed 14515068 words, keeping 355423 word types\n",
      "2020-03-15 14:53:52,960 : INFO : PROGRESS: at sentence #1970000, processed 14588033 words, keeping 355733 word types\n",
      "2020-03-15 14:53:52,977 : INFO : PROGRESS: at sentence #1980000, processed 14663025 words, keeping 356584 word types\n",
      "2020-03-15 14:53:52,991 : INFO : PROGRESS: at sentence #1990000, processed 14730064 words, keeping 357096 word types\n",
      "2020-03-15 14:53:53,008 : INFO : PROGRESS: at sentence #2000000, processed 14811930 words, keeping 357709 word types\n",
      "2020-03-15 14:53:53,026 : INFO : PROGRESS: at sentence #2010000, processed 14903648 words, keeping 358604 word types\n",
      "2020-03-15 14:53:53,041 : INFO : PROGRESS: at sentence #2020000, processed 14978703 words, keeping 359348 word types\n",
      "2020-03-15 14:53:53,056 : INFO : PROGRESS: at sentence #2030000, processed 15048048 words, keeping 359840 word types\n",
      "2020-03-15 14:53:53,073 : INFO : PROGRESS: at sentence #2040000, processed 15127773 words, keeping 360703 word types\n",
      "2020-03-15 14:53:53,085 : INFO : PROGRESS: at sentence #2050000, processed 15183725 words, keeping 361399 word types\n",
      "2020-03-15 14:53:53,099 : INFO : PROGRESS: at sentence #2060000, processed 15241830 words, keeping 362372 word types\n",
      "2020-03-15 14:53:53,115 : INFO : PROGRESS: at sentence #2070000, processed 15313162 words, keeping 362865 word types\n",
      "2020-03-15 14:53:53,132 : INFO : PROGRESS: at sentence #2080000, processed 15390937 words, keeping 363348 word types\n",
      "2020-03-15 14:53:53,151 : INFO : PROGRESS: at sentence #2090000, processed 15473074 words, keeping 364581 word types\n",
      "2020-03-15 14:53:53,169 : INFO : PROGRESS: at sentence #2100000, processed 15549581 words, keeping 365391 word types\n",
      "2020-03-15 14:53:53,178 : INFO : collected 365632 word types from a corpus of 15591018 raw words and 2106034 sentences\n",
      "2020-03-15 14:53:53,179 : INFO : Loading a fresh vocabulary\n",
      "2020-03-15 14:53:53,335 : INFO : effective_min_count=10 retains 57331 unique words (15% of original 365632, drops 308301)\n",
      "2020-03-15 14:53:53,335 : INFO : effective_min_count=10 leaves 14963846 word corpus (95% of original 15591018, drops 627172)\n",
      "2020-03-15 14:53:53,489 : INFO : deleting the raw counts dictionary of 365632 items\n",
      "2020-03-15 14:53:53,495 : INFO : sample=1e-05 downsamples 5871 most-common words\n",
      "2020-03-15 14:53:53,496 : INFO : downsampling leaves estimated 6621377 word corpus (44.2% of prior 14963846)\n",
      "2020-03-15 14:53:53,620 : INFO : estimated required memory for 57331 words and 1000 dimensions: 487313500 bytes\n",
      "2020-03-15 14:53:53,620 : INFO : resetting layer weights\n",
      "2020-03-15 14:54:01,873 : INFO : training model with 4 workers on 57331 vocabulary and 1000 features, using sg=0 hs=0 sample=1e-05 negative=5 window=10\n",
      "2020-03-15 14:54:02,905 : INFO : EPOCH 1 - PROGRESS: at 5.16% examples, 358619 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:03,908 : INFO : EPOCH 1 - PROGRESS: at 10.96% examples, 375202 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-15 14:54:04,929 : INFO : EPOCH 1 - PROGRESS: at 16.94% examples, 385746 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:05,932 : INFO : EPOCH 1 - PROGRESS: at 23.02% examples, 386080 words/s, in_qsize 7, out_qsize 1\n",
      "2020-03-15 14:54:06,962 : INFO : EPOCH 1 - PROGRESS: at 28.96% examples, 386915 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:07,965 : INFO : EPOCH 1 - PROGRESS: at 35.04% examples, 389526 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:08,973 : INFO : EPOCH 1 - PROGRESS: at 40.73% examples, 386006 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:09,981 : INFO : EPOCH 1 - PROGRESS: at 47.37% examples, 388721 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:11,030 : INFO : EPOCH 1 - PROGRESS: at 52.68% examples, 384226 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:12,040 : INFO : EPOCH 1 - PROGRESS: at 58.26% examples, 385398 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:13,053 : INFO : EPOCH 1 - PROGRESS: at 64.01% examples, 386562 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:14,059 : INFO : EPOCH 1 - PROGRESS: at 70.12% examples, 385534 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:15,065 : INFO : EPOCH 1 - PROGRESS: at 75.92% examples, 384532 words/s, in_qsize 8, out_qsize 0\n",
      "2020-03-15 14:54:16,075 : INFO : EPOCH 1 - PROGRESS: at 82.11% examples, 387402 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:17,083 : INFO : EPOCH 1 - PROGRESS: at 88.99% examples, 388185 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:18,094 : INFO : EPOCH 1 - PROGRESS: at 95.18% examples, 389218 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:18,849 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-15 14:54:18,871 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-15 14:54:18,876 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-15 14:54:18,879 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-15 14:54:18,880 : INFO : EPOCH - 1 : training on 15591018 raw words (6620963 effective words) took 17.0s, 389550 effective words/s\n",
      "2020-03-15 14:54:19,890 : INFO : EPOCH 2 - PROGRESS: at 5.48% examples, 390018 words/s, in_qsize 5, out_qsize 2\n",
      "2020-03-15 14:54:20,895 : INFO : EPOCH 2 - PROGRESS: at 11.34% examples, 391255 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:21,906 : INFO : EPOCH 2 - PROGRESS: at 17.35% examples, 396505 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:22,909 : INFO : EPOCH 2 - PROGRESS: at 23.14% examples, 390952 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:23,911 : INFO : EPOCH 2 - PROGRESS: at 29.17% examples, 394560 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:24,915 : INFO : EPOCH 2 - PROGRESS: at 34.86% examples, 391353 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:25,927 : INFO : EPOCH 2 - PROGRESS: at 40.68% examples, 388091 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:26,929 : INFO : EPOCH 2 - PROGRESS: at 47.00% examples, 388508 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:27,938 : INFO : EPOCH 2 - PROGRESS: at 51.92% examples, 383970 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:28,961 : INFO : EPOCH 2 - PROGRESS: at 57.32% examples, 382441 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:29,966 : INFO : EPOCH 2 - PROGRESS: at 62.80% examples, 380558 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:30,977 : INFO : EPOCH 2 - PROGRESS: at 67.97% examples, 379016 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:32,000 : INFO : EPOCH 2 - PROGRESS: at 73.57% examples, 376305 words/s, in_qsize 8, out_qsize 2\n",
      "2020-03-15 14:54:33,009 : INFO : EPOCH 2 - PROGRESS: at 78.86% examples, 374210 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:34,018 : INFO : EPOCH 2 - PROGRESS: at 84.04% examples, 372569 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:35,035 : INFO : EPOCH 2 - PROGRESS: at 90.44% examples, 370208 words/s, in_qsize 8, out_qsize 0\n",
      "2020-03-15 14:54:36,047 : INFO : EPOCH 2 - PROGRESS: at 95.34% examples, 368509 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:36,914 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-15 14:54:36,917 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-15 14:54:36,927 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-15 14:54:36,937 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-15 14:54:36,937 : INFO : EPOCH - 2 : training on 15591018 raw words (6623139 effective words) took 18.1s, 366930 effective words/s\n",
      "2020-03-15 14:54:37,950 : INFO : EPOCH 3 - PROGRESS: at 4.62% examples, 319940 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:38,952 : INFO : EPOCH 3 - PROGRESS: at 9.10% examples, 320389 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:39,996 : INFO : EPOCH 3 - PROGRESS: at 14.05% examples, 328520 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:41,005 : INFO : EPOCH 3 - PROGRESS: at 20.22% examples, 338581 words/s, in_qsize 5, out_qsize 2\n",
      "2020-03-15 14:54:42,031 : INFO : EPOCH 3 - PROGRESS: at 25.68% examples, 345882 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:43,049 : INFO : EPOCH 3 - PROGRESS: at 31.53% examples, 350447 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:44,067 : INFO : EPOCH 3 - PROGRESS: at 37.10% examples, 354425 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:45,069 : INFO : EPOCH 3 - PROGRESS: at 43.35% examples, 355708 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:46,108 : INFO : EPOCH 3 - PROGRESS: at 48.70% examples, 354405 words/s, in_qsize 8, out_qsize 1\n",
      "2020-03-15 14:54:47,114 : INFO : EPOCH 3 - PROGRESS: at 54.06% examples, 354958 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:48,127 : INFO : EPOCH 3 - PROGRESS: at 59.22% examples, 356492 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:49,134 : INFO : EPOCH 3 - PROGRESS: at 64.71% examples, 358717 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:50,164 : INFO : EPOCH 3 - PROGRESS: at 70.72% examples, 358513 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:51,188 : INFO : EPOCH 3 - PROGRESS: at 76.64% examples, 359541 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:52,198 : INFO : EPOCH 3 - PROGRESS: at 81.82% examples, 359131 words/s, in_qsize 8, out_qsize 1\n",
      "2020-03-15 14:54:53,213 : INFO : EPOCH 3 - PROGRESS: at 88.16% examples, 359589 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:54,236 : INFO : EPOCH 3 - PROGRESS: at 93.85% examples, 359796 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:55,254 : INFO : EPOCH 3 - PROGRESS: at 99.49% examples, 360045 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:55,299 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-15 14:54:55,319 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-15 14:54:55,324 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-15 14:54:55,325 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-15 14:54:55,325 : INFO : EPOCH - 3 : training on 15591018 raw words (6625528 effective words) took 18.4s, 360445 effective words/s\n",
      "2020-03-15 14:54:56,337 : INFO : EPOCH 4 - PROGRESS: at 4.97% examples, 349167 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:54:57,354 : INFO : EPOCH 4 - PROGRESS: at 10.26% examples, 355330 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:58,355 : INFO : EPOCH 4 - PROGRESS: at 15.34% examples, 359323 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:54:59,359 : INFO : EPOCH 4 - PROGRESS: at 21.16% examples, 358761 words/s, in_qsize 8, out_qsize 0\n",
      "2020-03-15 14:55:00,364 : INFO : EPOCH 4 - PROGRESS: at 26.57% examples, 362663 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:55:01,382 : INFO : EPOCH 4 - PROGRESS: at 32.10% examples, 359472 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:55:02,392 : INFO : EPOCH 4 - PROGRESS: at 37.10% examples, 357450 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:55:03,396 : INFO : EPOCH 4 - PROGRESS: at 43.04% examples, 355546 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:55:04,400 : INFO : EPOCH 4 - PROGRESS: at 48.56% examples, 357145 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:55:05,421 : INFO : EPOCH 4 - PROGRESS: at 53.80% examples, 355112 words/s, in_qsize 4, out_qsize 3\n",
      "2020-03-15 14:55:06,422 : INFO : EPOCH 4 - PROGRESS: at 58.92% examples, 357406 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-15 14:55:07,444 : INFO : EPOCH 4 - PROGRESS: at 64.53% examples, 359781 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:55:08,458 : INFO : EPOCH 4 - PROGRESS: at 70.30% examples, 358686 words/s, in_qsize 8, out_qsize 3\n",
      "2020-03-15 14:55:09,461 : INFO : EPOCH 4 - PROGRESS: at 75.57% examples, 357600 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:55:10,480 : INFO : EPOCH 4 - PROGRESS: at 81.12% examples, 357839 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:55:11,496 : INFO : EPOCH 4 - PROGRESS: at 86.16% examples, 355050 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:55:12,497 : INFO : EPOCH 4 - PROGRESS: at 91.86% examples, 353642 words/s, in_qsize 7, out_qsize 0\n",
      "2020-03-15 14:55:13,521 : INFO : EPOCH 4 - PROGRESS: at 96.60% examples, 352290 words/s, in_qsize 6, out_qsize 1\n",
      "2020-03-15 14:55:14,093 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-03-15 14:55:14,097 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-03-15 14:55:14,120 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-03-15 14:55:14,128 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-03-15 14:55:14,128 : INFO : EPOCH - 4 : training on 15591018 raw words (6621309 effective words) took 18.8s, 352312 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 1000    # Word vector dimensionality                      \n",
    "min_word_count = 10   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-5   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "print('Training model...')\n",
    "model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = 'propaganda-large-2'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test out the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to \"trump\":\n",
      "[('impeach', 0.9377140402793884), ('romney', 0.9375194311141968), ('supporters', 0.9333128333091736), ('newt', 0.9302890300750732), ('gingrich', 0.9285157322883606), ('bitter', 0.9285004138946533), ('behna', 0.9277978539466858), ('tantrum', 0.9268388152122498), ('forgets', 0.9253718256950378), ('temper', 0.9249578714370728)]\n",
      "\n",
      "Most similar to \"hillary\":\n",
      "[('clinton', 0.951890230178833), ('podestaemails', 0.9492028951644897), ('dnc', 0.9432393312454224), ('hillarysemails', 0.9405421018600464), ('dncleak', 0.9361636638641357), ('lied', 0.9330999851226807), ('bff', 0.9328992962837219), ('susanrice', 0.9327013492584229), ('crooked', 0.9313591122627258), ('crookedhillary', 0.9278271198272705)]\n",
      "\n",
      "Most similar to \"obama\":\n",
      "[('undermine', 0.9506447315216064), ('hostile', 0.9470846652984619), ('agreed', 0.9441496729850769), ('admin', 0.9425696134567261), ('directly', 0.9397111535072327), ('treason', 0.939399242401123), ('tactics', 0.9370774030685425), ('purge', 0.935573935508728), ('operatives', 0.935323178768158), ('venezuelan', 0.9337773323059082)]\n",
      "\n",
      "Most similar to \"immigrant\":\n",
      "[('aclu', 0.9692915678024292), ('enforcement', 0.9683163166046143), ('profiling', 0.9604897499084473), ('intimidation', 0.9603440165519714), ('forcing', 0.959051787853241), ('enforcing', 0.9572352170944214), ('law', 0.9568201899528503), ('katesteinle', 0.9547489881515503), ('deportation', 0.9537555575370789), ('activists', 0.9498047828674316)]\n",
      "\n",
      "Most similar to \"muslim\":\n",
      "[('muslims', 0.9583717584609985), ('sharia', 0.9528225064277649), ('islamophobia', 0.9502997994422913), ('christians', 0.9436268210411072), ('banislam', 0.9367510080337524), ('genocide', 0.9302086234092712), ('terrorist', 0.9291372299194336), ('jews', 0.9268813133239746), ('jihad', 0.9256013631820679), ('religionofpeace', 0.9255349636077881)]\n",
      "\n",
      "Most similar to \"media\":\n",
      "[('mainstream', 0.9683625102043152), ('narrative', 0.9462391138076782), ('hacks', 0.945206880569458), ('censoring', 0.9432496428489685), ('markdice', 0.9377658367156982), ('playbook', 0.9282497763633728), ('outlets', 0.9275039434432983), ('censor', 0.9273574352264404), ('fake', 0.9261982440948486), ('outlet', 0.9235149621963501)]\n",
      "\n",
      "Most similar to \"abortions\":\n",
      "[('abortion', 0.9657011032104492), ('defunding', 0.9602264761924744), ('punishing', 0.9586036801338196), ('recipients', 0.9504983425140381), ('allowing', 0.9481834769248962), ('mayors', 0.9458838701248169), ('campuses', 0.9416486024856567), ('planned', 0.9411401748657227), ('illegals', 0.9411043524742126), ('requiring', 0.9404726624488831)]\n",
      "\n",
      "Most similar to \"russia\":\n",
      "[('russian', 0.9372832775115967), ('putin', 0.9338807463645935), ('kremlin', 0.9306380748748779), ('intelligence', 0.9209041595458984), ('interference', 0.9005064368247986), ('ambassador', 0.8960090279579163), ('vladimir', 0.8945913910865784), ('cia', 0.8922407627105713), ('spy', 0.891815721988678), ('diplomats', 0.8858888745307922)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Most similar to \"trump\":')\n",
    "print(model.wv.most_similar('trump'), end='\\n\\n')\n",
    "\n",
    "print('Most similar to \"hillary\":')\n",
    "print(model.wv.most_similar('hillary'), end='\\n\\n')\n",
    "\n",
    "print('Most similar to \"obama\":')\n",
    "print(model.wv.most_similar('obama'), end='\\n\\n')\n",
    "\n",
    "print('Most similar to \"immigrant\":')\n",
    "print(model.wv.most_similar('immigrant'), end='\\n\\n')\n",
    "\n",
    "print('Most similar to \"muslim\":')\n",
    "print(model.wv.most_similar('muslim'), end='\\n\\n')\n",
    "\n",
    "print('Most similar to \"media\":')\n",
    "print(model.wv.most_similar('media'), end='\\n\\n')\n",
    "\n",
    "print('Most similar to \"abortions\":')\n",
    "print(model.wv.most_similar('abortions'), end='\\n\\n')\n",
    "\n",
    "print('Most similar to \"russia\":')\n",
    "print(model.wv.most_similar('russia'), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vladimir', 0.9627082347869873),\n",
       " ('russia', 0.9338808655738831),\n",
       " ('kremlin', 0.8904656767845154),\n",
       " ('lavrov', 0.8867936730384827),\n",
       " ('sochitalks', 0.8861778974533081),\n",
       " ('kerry', 0.8700426816940308),\n",
       " ('aggression', 0.8657740354537964),\n",
       " ('assad', 0.8646084666252136),\n",
       " ('ukraine', 0.8645811080932617),\n",
       " ('nk', 0.8620179891586304)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
